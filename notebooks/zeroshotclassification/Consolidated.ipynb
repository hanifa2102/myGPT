{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d80fde-d1a4-412d-a082-2ba66b033b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets evaluate transformers[sentencepiece]\n",
    "# !pip install torch \n",
    "# pip install accelerate xformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7da4f3-f0a0-419e-935a-e47ca9ac6264",
   "metadata": {},
   "source": [
    "## Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd634bad-6bbf-4ac7-81ef-34b11699482f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf61caa-6fc9-4448-adf7-d0b79c8661e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# import bamboolib as bam\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "787fa45a-7471-4f2e-b024-656bf34ff725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2934a9a-b8d3-4c13-abd8-6fe1a0cfa489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# num_gpus = torch.cuda.device_count()\n",
    "\n",
    "# for i in range(num_gpus):\n",
    "#     device = torch.cuda.get_device_name(i)\n",
    "#     print(f\"GPU {i}: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa04623-68d9-46ab-9c6d-488755271a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa5624-c74b-44fa-a8e9-f9e910ce9580",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    " - https://blog.paperspace.com/zero-shot-text-classification-with-hugging-face-on-gradient/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532297a6-c5e1-4bed-b6dd-b019d445e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# classifier = pipeline(\n",
    "#                       task=\"zero-shot-classification\",\n",
    "#                       device=0,\n",
    "#                       model=\"facebook/bart-large-mnli\",\n",
    "#                     )\n",
    "# print(f'Model Used is :\\t{classifier.model.name_or_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b915745d-6c19-484d-9d04-fdaa30b65781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'],\n",
      " 'scores': [0.5036355257034302,\n",
      "            0.47879961133003235,\n",
      "            0.012600339017808437,\n",
      "            0.0026557771489024162,\n",
      "            0.002308764262124896],\n",
      " 'sequence': 'I have a problem with my iphone that needs to be resolved asap!!'}\n",
      "{'labels': ['english', 'german'],\n",
      " 'scores': [0.8135163187980652, 0.18648362159729004],\n",
      " 'sequence': 'I have a problem with my iphone that needs to be resolved asap!!'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "classifier = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "predictions=classifier(\n",
    "    \"I have a problem with my iphone that needs to be resolved asap!!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
    ")\n",
    "pprint.pprint(predictions)\n",
    "predictions=classifier(\n",
    "    \"I have a problem with my iphone that needs to be resolved asap!!\",\n",
    "    candidate_labels=[\"english\", \"german\"],\n",
    ")\n",
    "pprint.pprint(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6480a402-b5a3-47e1-850f-028710fd4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pprint\n",
    "\n",
    "# text_piece = \"The food at this place is really good.\"\n",
    "# labels = [\"Food\", \"Employee\", \"Restaurant\", \"Party\", \"Nature\", \"Car\"]\n",
    "\n",
    "# predictions = classifier(text_piece, labels, multi_label=True)\n",
    "# pprint.pprint(predictions)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d22e4ca4-9de2-471c-9e96-666bda0c8123",
   "metadata": {},
   "source": [
    "\n",
    "Default_template => \"<cls> sequence to classify <sep> This example is sports . <sep>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5813cf0a-381a-4635-80de-9ad330c8baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': ['Food', 'Restaurant', 'Employee', 'Car', 'Party', 'Nature'],\n",
      " 'scores': [0.6570188403129578,\n",
      "            0.15241312980651855,\n",
      "            0.1027577593922615,\n",
      "            0.04373770207166672,\n",
      "            0.027072450146079063,\n",
      "            0.01700015179812908],\n",
      " 'sequence': 'The food at this place is really good.'}\n",
      "\n",
      "With template:This is a good place to hold a {}\t\n",
      "{'labels': ['Food', 'Restaurant', 'Employee', 'Nature', 'Car', 'Party'],\n",
      " 'scores': [0.5115107297897339,\n",
      "            0.28234797716140747,\n",
      "            0.08783061802387238,\n",
      "            0.04445023089647293,\n",
      "            0.04209845885634422,\n",
      "            0.03176198899745941],\n",
      " 'sequence': 'The food at this place is really good.'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "text_piece = \"The food at this place is really good.\"\n",
    "labels = [\"Food\", \"Employee\", \"Restaurant\", \"Party\", \"Nature\", \"Car\"]\n",
    "\n",
    "predictions = classifier(text_piece,labels)\n",
    "pprint.pprint(predictions)\n",
    "\n",
    "template = \"This is a good place to hold a {}\"\n",
    "predictions = classifier(text_piece,labels,hypothesis_template=template)\n",
    "\n",
    "print(f'\\nWith template:{template}\\t')\n",
    "pprint.pprint(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1893b877-66bb-4d7c-ab0b-61c06fb746c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': ['Positive', 'Neutral', 'Negative'],\n",
      " 'scores': [0.9758098721504211, 0.1689709722995758, 0.0006603864021599293],\n",
      " 'sequence': 'The food at this place is really good.'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "text_piece = \"The food at this place is really good.\"\n",
    "labels = [\"Positive\", \"Negative\", \"Neutral\"]\n",
    "template = \"The sentiment of this review is {}\"\n",
    "predictions = classifier(text_piece, \n",
    "           labels, \n",
    "           hypothesis_template=template,multi_label=True\n",
    "           )\n",
    "pprint.pprint(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53f6d2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': ['EU', 'economy', 'environment', 'entertainment'],\n",
      " 'scores': [0.7078127861022949,\n",
      "            0.12032690644264221,\n",
      "            0.09738077223300934,\n",
      "            0.07447956502437592],\n",
      " 'sequence': 'Angela Merkel is a politician in Germany and leader of the CDU'}\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")\n",
    "sequence_to_classify = \"Angela Merkel is a politician in Germany and leader of the CDU\"\n",
    "candidate_labels = [\"EU\", \"economy\", \"entertainment\", \"environment\"]\n",
    "output = classifier(sequence_to_classify, candidate_labels, multi_label=False)\n",
    "pprint.pprint(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e1a3475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]]),\n",
      " 'input_ids': tensor([[    1,   273,   362,   708,   272,   273,  3172,   262,  1421,   261,\n",
      "           304,  1064,   567,   708,   278,   284,   675, 10650,   260,     2,\n",
      "           279,  1421,   284,   397,   260,     2]]),\n",
      " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "         1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "premise = \"I first thought that I liked the movie, but upon second thought it was actually disappointing.\"\n",
    "hypothesis = \"The movie was good.\"\n",
    "\n",
    "input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "pprint.pprint(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba02e546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0397d633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None,\n",
      "                         logits=tensor([[-1.1314, -0.1597,  1.3201]], grad_fn=<AddmmBackward0>),\n",
      "                         hidden_states=None,\n",
      "                         attentions=None)\n"
     ]
    }
   ],
   "source": [
    "output = model(input[\"input_ids\"])  # device = \"cuda:0\" or \"cpu\"\n",
    "pprint.pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7a6e4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06558263301849365, 0.17330026626586914, 0.7611171007156372]\n"
     ]
    }
   ],
   "source": [
    "prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "pprint.pprint(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42fa950f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entailment': 6.6, 'neutral': 17.3, 'contradiction': 76.1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cafc954-8944-4a99-af6b-0eef79928402",
   "metadata": {},
   "source": [
    "# PlayGround"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af13af8-f663-4ab2-82e0-19dc4c994a9e",
   "metadata": {},
   "source": [
    "## Global Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff31afc7-d0c8-4ee2-b0b0-2349ccf3db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "  prdt_list=['Fluke Gold Level Extended Warranty',\n",
    "            'mailing machine rental',\n",
    "            'Punch, 2-Hole, 20 SHT,BKSV',\n",
    "            'HP 5-YR NBD Onsite DMR DT Only SVC',\n",
    "            'V7550 Splicing Device',\n",
    "            'Treehouse Annual Software Maintenance',\n",
    "            'Curve Fitting Toolbox Maintenance (SUBCF)',\n",
    "            'HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND STAND FOR THE HP M750DN CO',\n",
    "            'Maintenance DB/Text',\n",
    "            'bloomberg Terminal',\n",
    "            'TONER DRUM CARTRIDGES',\n",
    "            '9000258Y, MXM453UJ, LASSEN PROG OFFICE',\n",
    "            'Nexpose Shared Perimeter Security Engine Up To 256 IPs',\n",
    "            '2 Year Secure Site SSL Cert #00006856',\n",
    "            'Fluke Standard Maintenance Advanced package',\n",
    "            'REPLACEMENT RIBBON',\n",
    "            'LANDESK SOFTWARE',\n",
    "            'Exec - IT',\n",
    "            'X-Stamper Custom Message Stamp',\n",
    "            'TeamSite Server Dual CPU Annual Std. Maintenance']\n",
    "  prdt_labels=['Communications Devices and Accessories',\n",
    "          'Components for information technology or broadcasting or telecommunications',\n",
    "          'Computer Equipment and Accessories',\n",
    "          'Data Voice or Multimedia Network Equipment or Platforms and Accessories',\n",
    "          'Software',\n",
    "          'Printing and publishing equipment',\n",
    "          'Audio and visual presentation and composing equipment',\n",
    "          'Human resources services',\n",
    "          'Legal services',\n",
    "          'Real estate services',\n",
    "          'Business administration services',\n",
    "          'Professional engineering services',\n",
    "          'Computer services',\n",
    "          'Information Technology Service Delivery',\n",
    "          'Advertising',\n",
    "          'Writing and translations',\n",
    "          'Telecommunications media services',\n",
    "          'Information services',\n",
    "          'Unknown']\n",
    "  return (prdt_list,prdt_labels)\n",
    "\n",
    "def test_classifier(classifier):\n",
    "      print(f'Model Used is :\\t{classifier.model.name_or_path}')\n",
    "      display(classifier(\n",
    "        [\"This is a course about the Transformers library\",\"I expect to be big entrepreneur soon\"],\n",
    "        candidate_labels=[\"education\", \"politics\", \"business\"],multi_label=True))\n",
    "    \n",
    "def run_zero_shot(classifier):\n",
    "  prdt_list=get_data()[0]\n",
    "  prdt_labels=get_data()[1]\n",
    "  template = \"This product should be classified as {}\"\n",
    "  results=classifier(sequences=prdt_list,candidate_labels=prdt_labels,hypothesis_template=template)\n",
    "  df=pd.DataFrame([(result['sequence'],result['labels'][0],result['scores'][0]) for result in results])\n",
    "  return df\n",
    "\n",
    "# def get_model(model_name):\n",
    "#   classifier=pipeline('zero-shot-classification',model=model_name)\n",
    "#   # classifier = pipeline(\"zero-shot-classification\",model=model_name,torch_dtype=torch.float16,device_map=\"auto\",trust_remote_code=True)\n",
    "#   print(f'Model Used is :\\t{classifier.model.name_or_path}')\n",
    "#   print(classifier(\n",
    "#     \"This is a course about the Transformers library\",\n",
    "#     candidate_labels=[\"education\", \"politics\", \"business\"]))\n",
    "#   return classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4adc9e-477c-4813-aa18-643252c204c5",
   "metadata": {},
   "source": [
    "## Try various Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f6558-fcf7-4fbe-9331-5835d667cb60",
   "metadata": {},
   "source": [
    "### Zeroshot models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3813e24-357b-4b8e-a578-c34ebf7f56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier=pipeline(\"zero-shot-classification\",device=0)\n",
    "# test_classifier(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1e74c95-8fba-404c-b2ae-be9a5b8cdc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Used is :\tfacebook/bart-large-mnli\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'This is a course about the Transformers library',\n",
       "  'labels': ['education', 'business', 'politics'],\n",
       "  'scores': [0.25892317295074463,\n",
       "   0.000499170389957726,\n",
       "   9.329070599051192e-05]},\n",
       " {'sequence': 'I expect to be big entrepreneur soon',\n",
       "  'labels': ['business', 'education', 'politics'],\n",
       "  'scores': [0.9819421172142029,\n",
       "   0.00015833442739676684,\n",
       "   0.00012242168304510415]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fluke Gold Level Extended Warranty</td>\n",
       "      <td>Telecommunications media services</td>\n",
       "      <td>0.122657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mailing machine rental</td>\n",
       "      <td>Printing and publishing equipment</td>\n",
       "      <td>0.236928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Punch, 2-Hole, 20 SHT,BKSV</td>\n",
       "      <td>Telecommunications media services</td>\n",
       "      <td>0.116983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 5-YR NBD Onsite DMR DT Only SVC</td>\n",
       "      <td>Human resources services</td>\n",
       "      <td>0.080905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V7550 Splicing Device</td>\n",
       "      <td>Professional engineering services</td>\n",
       "      <td>0.128924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Treehouse Annual Software Maintenance</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.262744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Curve Fitting Toolbox Maintenance (SUBCF)</td>\n",
       "      <td>Professional engineering services</td>\n",
       "      <td>0.231003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND...</td>\n",
       "      <td>Printing and publishing equipment</td>\n",
       "      <td>0.290372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Maintenance DB/Text</td>\n",
       "      <td>Writing and translations</td>\n",
       "      <td>0.225088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bloomberg Terminal</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.164763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TONER DRUM CARTRIDGES</td>\n",
       "      <td>Telecommunications media services</td>\n",
       "      <td>0.133536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9000258Y, MXM453UJ, LASSEN PROG OFFICE</td>\n",
       "      <td>Business administration services</td>\n",
       "      <td>0.089342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nexpose Shared Perimeter Security Engine Up To...</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.104918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2 Year Secure Site SSL Cert #00006856</td>\n",
       "      <td>Information Technology Service Delivery</td>\n",
       "      <td>0.097257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fluke Standard Maintenance Advanced package</td>\n",
       "      <td>Professional engineering services</td>\n",
       "      <td>0.177791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>REPLACEMENT RIBBON</td>\n",
       "      <td>Professional engineering services</td>\n",
       "      <td>0.202491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LANDESK SOFTWARE</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.368844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Exec - IT</td>\n",
       "      <td>Information services</td>\n",
       "      <td>0.151005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X-Stamper Custom Message Stamp</td>\n",
       "      <td>Telecommunications media services</td>\n",
       "      <td>0.140988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TeamSite Server Dual CPU Annual Std. Maintenance</td>\n",
       "      <td>Computer services</td>\n",
       "      <td>0.095393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0  \\\n",
       "0                  Fluke Gold Level Extended Warranty   \n",
       "1                              mailing machine rental   \n",
       "2                          Punch, 2-Hole, 20 SHT,BKSV   \n",
       "3                  HP 5-YR NBD Onsite DMR DT Only SVC   \n",
       "4                               V7550 Splicing Device   \n",
       "5               Treehouse Annual Software Maintenance   \n",
       "6           Curve Fitting Toolbox Maintenance (SUBCF)   \n",
       "7   HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND...   \n",
       "8                                 Maintenance DB/Text   \n",
       "9                                  bloomberg Terminal   \n",
       "10                              TONER DRUM CARTRIDGES   \n",
       "11             9000258Y, MXM453UJ, LASSEN PROG OFFICE   \n",
       "12  Nexpose Shared Perimeter Security Engine Up To...   \n",
       "13              2 Year Secure Site SSL Cert #00006856   \n",
       "14        Fluke Standard Maintenance Advanced package   \n",
       "15                                 REPLACEMENT RIBBON   \n",
       "16                                   LANDESK SOFTWARE   \n",
       "17                                          Exec - IT   \n",
       "18                     X-Stamper Custom Message Stamp   \n",
       "19   TeamSite Server Dual CPU Annual Std. Maintenance   \n",
       "\n",
       "                                                    1         2  \n",
       "0                   Telecommunications media services  0.122657  \n",
       "1                   Printing and publishing equipment  0.236928  \n",
       "2                   Telecommunications media services  0.116983  \n",
       "3                            Human resources services  0.080905  \n",
       "4                   Professional engineering services  0.128924  \n",
       "5                                            Software  0.262744  \n",
       "6                   Professional engineering services  0.231003  \n",
       "7                   Printing and publishing equipment  0.290372  \n",
       "8                            Writing and translations  0.225088  \n",
       "9   Components for information technology or broad...  0.164763  \n",
       "10                  Telecommunications media services  0.133536  \n",
       "11                   Business administration services  0.089342  \n",
       "12                                           Software  0.104918  \n",
       "13            Information Technology Service Delivery  0.097257  \n",
       "14                  Professional engineering services  0.177791  \n",
       "15                  Professional engineering services  0.202491  \n",
       "16                                           Software  0.368844  \n",
       "17                               Information services  0.151005  \n",
       "18                  Telecommunications media services  0.140988  \n",
       "19                                  Computer services  0.095393  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=pipeline(\"zero-shot-classification\",model='facebook/bart-large-mnli',device=0)\n",
    "test_classifier(classifier)\n",
    "df_bart=run_zero_shot(classifier)\n",
    "df_bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd0322b-fdd6-4e23-aea4-5bee8028ebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Used is :\tsjrhuschlee/flan-t5-base-mnli\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'This is a course about the Transformers library',\n",
       "  'labels': ['education', 'business', 'politics'],\n",
       "  'scores': [0.9717826843261719,\n",
       "   0.00015134767454583198,\n",
       "   7.653246575500816e-05]},\n",
       " {'sequence': 'I expect to be big entrepreneur soon',\n",
       "  'labels': ['business', 'education', 'politics'],\n",
       "  'scores': [0.9917102456092834,\n",
       "   0.028074581176042557,\n",
       "   0.00023239631264004856]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fluke Gold Level Extended Warranty</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.256011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mailing machine rental</td>\n",
       "      <td>Printing and publishing equipment</td>\n",
       "      <td>0.219789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Punch, 2-Hole, 20 SHT,BKSV</td>\n",
       "      <td>Audio and visual presentation and composing eq...</td>\n",
       "      <td>0.256792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 5-YR NBD Onsite DMR DT Only SVC</td>\n",
       "      <td>Printing and publishing equipment</td>\n",
       "      <td>0.140350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V7550 Splicing Device</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.216191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Treehouse Annual Software Maintenance</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.416034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Curve Fitting Toolbox Maintenance (SUBCF)</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.324222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND...</td>\n",
       "      <td>Printing and publishing equipment</td>\n",
       "      <td>0.352397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Maintenance DB/Text</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.374102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bloomberg Terminal</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.249234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TONER DRUM CARTRIDGES</td>\n",
       "      <td>Printing and publishing equipment</td>\n",
       "      <td>0.218804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9000258Y, MXM453UJ, LASSEN PROG OFFICE</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.181778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nexpose Shared Perimeter Security Engine Up To...</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.241355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2 Year Secure Site SSL Cert #00006856</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.310146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fluke Standard Maintenance Advanced package</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.327649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>REPLACEMENT RIBBON</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.218114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LANDESK SOFTWARE</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.382474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Exec - IT</td>\n",
       "      <td>Information services</td>\n",
       "      <td>0.218038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X-Stamper Custom Message Stamp</td>\n",
       "      <td>Audio and visual presentation and composing eq...</td>\n",
       "      <td>0.268461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TeamSite Server Dual CPU Annual Std. Maintenance</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.338475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0  \\\n",
       "0                  Fluke Gold Level Extended Warranty   \n",
       "1                              mailing machine rental   \n",
       "2                          Punch, 2-Hole, 20 SHT,BKSV   \n",
       "3                  HP 5-YR NBD Onsite DMR DT Only SVC   \n",
       "4                               V7550 Splicing Device   \n",
       "5               Treehouse Annual Software Maintenance   \n",
       "6           Curve Fitting Toolbox Maintenance (SUBCF)   \n",
       "7   HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND...   \n",
       "8                                 Maintenance DB/Text   \n",
       "9                                  bloomberg Terminal   \n",
       "10                              TONER DRUM CARTRIDGES   \n",
       "11             9000258Y, MXM453UJ, LASSEN PROG OFFICE   \n",
       "12  Nexpose Shared Perimeter Security Engine Up To...   \n",
       "13              2 Year Secure Site SSL Cert #00006856   \n",
       "14        Fluke Standard Maintenance Advanced package   \n",
       "15                                 REPLACEMENT RIBBON   \n",
       "16                                   LANDESK SOFTWARE   \n",
       "17                                          Exec - IT   \n",
       "18                     X-Stamper Custom Message Stamp   \n",
       "19   TeamSite Server Dual CPU Annual Std. Maintenance   \n",
       "\n",
       "                                                    1         2  \n",
       "0   Components for information technology or broad...  0.256011  \n",
       "1                   Printing and publishing equipment  0.219789  \n",
       "2   Audio and visual presentation and composing eq...  0.256792  \n",
       "3                   Printing and publishing equipment  0.140350  \n",
       "4   Components for information technology or broad...  0.216191  \n",
       "5                                            Software  0.416034  \n",
       "6   Components for information technology or broad...  0.324222  \n",
       "7                   Printing and publishing equipment  0.352397  \n",
       "8   Components for information technology or broad...  0.374102  \n",
       "9   Components for information technology or broad...  0.249234  \n",
       "10                  Printing and publishing equipment  0.218804  \n",
       "11  Components for information technology or broad...  0.181778  \n",
       "12  Components for information technology or broad...  0.241355  \n",
       "13  Components for information technology or broad...  0.310146  \n",
       "14  Components for information technology or broad...  0.327649  \n",
       "15  Components for information technology or broad...  0.218114  \n",
       "16                                           Software  0.382474  \n",
       "17                               Information services  0.218038  \n",
       "18  Audio and visual presentation and composing eq...  0.268461  \n",
       "19  Components for information technology or broad...  0.338475  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=pipeline(\"zero-shot-classification\",model='sjrhuschlee/flan-t5-base-mnli',trust_remote_code=True,device=0)\n",
    "test_classifier(classifier)\n",
    "df_flan=run_zero_shot(classifier)\n",
    "df_flan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7010e72-56ac-40c0-9e65-b50343fdfd0c",
   "metadata": {},
   "source": [
    "- **Kills the kernel, try with bigger GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50212f91-ffb1-4272-a26c-4084bdb81a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e048dd483b455682978ed7a199c9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier=pipeline(\"zero-shot-classification\",model='Bschleter/llama-2-7b-hermes-financecompliance',torch_dtype=torch.float16,device_map=\"auto\")\n",
    "test_classifier(classifier)\n",
    "df_llama_hermes=run_zero_shot(classifier)\n",
    "df_llama_hermes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab14829-6a22-471b-8f0d-40cb0d8c3abc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Non-zero shot models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877aabdf-0195-41cf-acaf-28a2b713fc90",
   "metadata": {},
   "source": [
    "- llama-2 not possible to use for zero-shot classification\n",
    "- Need to fine tune on mnli dataset (probably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cf9c74a-d124-468b-aed2-04e9e80d5457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a763e20778b4586ad9cf0ba7f26ecbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5eec5e62a445649b38f26ecdfaf323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759e947e32f245dd9c814cbe0b7b9815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10bb929191f477aafa7f419a87659c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864ac89c11a340d180761c1e5f235fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e2dd7f0f064a03b77f586240a10879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c129119d5124b6584feb161e63e4b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Used is :\tgoogle/flan-t5-base\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You have to specify either decoder_input_ids or decoder_inputs_embeds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m classifier\u001b[38;5;241m=\u001b[39mpipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m,model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoogle/flan-t5-base\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtest_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_flan_chat\u001b[38;5;241m=\u001b[39mrun_zero_shot(classifier)\n\u001b[1;32m      4\u001b[0m df_flan_chat\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mtest_classifier\u001b[0;34m(classifier)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_classifier\u001b[39m(classifier):\n\u001b[1;32m      2\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Used is :\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mclassifier\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mname_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m       display(\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThis is a course about the Transformers library\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI expect to be big entrepreneur soon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meducation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpolitics\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbusiness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/pipelines/zero_shot_classification.py:205\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/pipelines/base.py:1103\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1100\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1101\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1102\u001b[0m     )\n\u001b[0;32m-> 1103\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 266\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/pipelines/base.py:1028\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1027\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1028\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/pipelines/zero_shot_classification.py:224\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline._forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    222\u001b[0m sequence \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    223\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m {k: inputs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mmodel_input_names}\n\u001b[0;32m--> 224\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_label\u001b[39m\u001b[38;5;124m\"\u001b[39m: candidate_label,\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m: sequence,\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutputs,\n\u001b[1;32m    231\u001b[0m }\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1717\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1714\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1717\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1732\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:987\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m     err_msg_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 987\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124minput_ids or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: You have to specify either decoder_input_ids or decoder_inputs_embeds"
     ]
    }
   ],
   "source": [
    "classifier=pipeline(\"zero-shot-classification\",model='google/flan-t5-base')\n",
    "test_classifier(classifier)\n",
    "df_flan_chat=run_zero_shot(classifier)\n",
    "df_flan_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1bc7775-af8f-49b8-acd1-340954050ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48155b6dcac4c009ebdc88e6242ccd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d0c6abd8e34a8c929eafa738afa736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc20f824359469ca42234ed67d04eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ba224e64614f3cbcd0dcf9fc4ae92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d00217142574667a6a1f203cc67c8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1588b27d937440109416b602d760226f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-chat-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b24df06bd042a7b59ce2409c4c57b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d794bd92f23d45f3b8afb9b7272b9006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001771f42b8c4cfaac3ead0ea9519121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90532448f9d24b4b820552899212b6cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Using pad_token, but it is not set yet.\n",
      "Tokenizer was not supporting padding necessary for zero-shot, attempting to use  `pad_token=eos_token`\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Used is :\tmeta-llama/Llama-2-7b-chat-hf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'This is a course about the Transformers library',\n",
       "  'labels': ['politics', 'education', 'business'],\n",
       "  'scores': [0.38658690452575684, 0.36387479305267334, 0.2495383322238922]},\n",
       " {'sequence': 'I expect to be big entrepreneur soon',\n",
       "  'labels': ['education', 'politics', 'business'],\n",
       "  'scores': [0.5809245109558105, 0.25718650221824646, 0.161888986825943]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fluke Gold Level Extended Warranty</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.170759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mailing machine rental</td>\n",
       "      <td>Computer Equipment and Accessories</td>\n",
       "      <td>0.095694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Punch, 2-Hole, 20 SHT,BKSV</td>\n",
       "      <td>Data Voice or Multimedia Network Equipment or ...</td>\n",
       "      <td>0.062951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 5-YR NBD Onsite DMR DT Only SVC</td>\n",
       "      <td>Data Voice or Multimedia Network Equipment or ...</td>\n",
       "      <td>0.072345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V7550 Splicing Device</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.190659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Treehouse Annual Software Maintenance</td>\n",
       "      <td>Computer Equipment and Accessories</td>\n",
       "      <td>0.108944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Curve Fitting Toolbox Maintenance (SUBCF)</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.203226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.061821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Maintenance DB/Text</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.102357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bloomberg Terminal</td>\n",
       "      <td>Computer Equipment and Accessories</td>\n",
       "      <td>0.110765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TONER DRUM CARTRIDGES</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.142057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9000258Y, MXM453UJ, LASSEN PROG OFFICE</td>\n",
       "      <td>Data Voice or Multimedia Network Equipment or ...</td>\n",
       "      <td>0.070999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nexpose Shared Perimeter Security Engine Up To...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.211027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2 Year Secure Site SSL Cert #00006856</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.157274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fluke Standard Maintenance Advanced package</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.122522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>REPLACEMENT RIBBON</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.162733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LANDESK SOFTWARE</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.100687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Exec - IT</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.084534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X-Stamper Custom Message Stamp</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.146738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TeamSite Server Dual CPU Annual Std. Maintenance</td>\n",
       "      <td>Computer Equipment and Accessories</td>\n",
       "      <td>0.167001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0  \\\n",
       "0                  Fluke Gold Level Extended Warranty   \n",
       "1                              mailing machine rental   \n",
       "2                          Punch, 2-Hole, 20 SHT,BKSV   \n",
       "3                  HP 5-YR NBD Onsite DMR DT Only SVC   \n",
       "4                               V7550 Splicing Device   \n",
       "5               Treehouse Annual Software Maintenance   \n",
       "6           Curve Fitting Toolbox Maintenance (SUBCF)   \n",
       "7   HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND...   \n",
       "8                                 Maintenance DB/Text   \n",
       "9                                  bloomberg Terminal   \n",
       "10                              TONER DRUM CARTRIDGES   \n",
       "11             9000258Y, MXM453UJ, LASSEN PROG OFFICE   \n",
       "12  Nexpose Shared Perimeter Security Engine Up To...   \n",
       "13              2 Year Secure Site SSL Cert #00006856   \n",
       "14        Fluke Standard Maintenance Advanced package   \n",
       "15                                 REPLACEMENT RIBBON   \n",
       "16                                   LANDESK SOFTWARE   \n",
       "17                                          Exec - IT   \n",
       "18                     X-Stamper Custom Message Stamp   \n",
       "19   TeamSite Server Dual CPU Annual Std. Maintenance   \n",
       "\n",
       "                                                    1         2  \n",
       "0                                         Advertising  0.170759  \n",
       "1                  Computer Equipment and Accessories  0.095694  \n",
       "2   Data Voice or Multimedia Network Equipment or ...  0.062951  \n",
       "3   Data Voice or Multimedia Network Equipment or ...  0.072345  \n",
       "4                                         Advertising  0.190659  \n",
       "5                  Computer Equipment and Accessories  0.108944  \n",
       "6                                            Software  0.203226  \n",
       "7                                             Unknown  0.061821  \n",
       "8                                            Software  0.102357  \n",
       "9                  Computer Equipment and Accessories  0.110765  \n",
       "10                                            Unknown  0.142057  \n",
       "11  Data Voice or Multimedia Network Equipment or ...  0.070999  \n",
       "12                                            Unknown  0.211027  \n",
       "13                                        Advertising  0.157274  \n",
       "14                                        Advertising  0.122522  \n",
       "15                                        Advertising  0.162733  \n",
       "16                                           Software  0.100687  \n",
       "17                                        Advertising  0.084534  \n",
       "18                                        Advertising  0.146738  \n",
       "19                 Computer Equipment and Accessories  0.167001  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=pipeline(\"zero-shot-classification\",model='meta-llama/Llama-2-7b-chat-hf',torch_dtype=torch.float16,device_map=\"auto\",)\n",
    "test_classifier(classifier)\n",
    "df_llama_chat=run_zero_shot(classifier)\n",
    "df_llama_chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
