{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d80fde-d1a4-412d-a082-2ba66b033b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets evaluate transformers[sentencepiece]\n",
    "# !pip install torch \n",
    "# pip install accelerate xformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7da4f3-f0a0-419e-935a-e47ca9ac6264",
   "metadata": {},
   "source": [
    "## Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd634bad-6bbf-4ac7-81ef-34b11699482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# from IPython.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf61caa-6fc9-4448-adf7-d0b79c8661e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# import bamboolib as bam\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787fa45a-7471-4f2e-b024-656bf34ff725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2934a9a-b8d3-4c13-abd8-6fe1a0cfa489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "for i in range(num_gpus):\n",
    "    device = torch.cuda.get_device_name(i)\n",
    "    print(f\"GPU {i}: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afa04623-68d9-46ab-9c6d-488755271a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa5624-c74b-44fa-a8e9-f9e910ce9580",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    " - https://blog.paperspace.com/zero-shot-text-classification-with-hugging-face-on-gradient/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "532297a6-c5e1-4bed-b6dd-b019d445e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\n",
    "                      task=\"zero-shot-classification\",\n",
    "                      device=0,\n",
    "                      model=\"facebook/bart-large-mnli\",\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6480a402-b5a3-47e1-850f-028710fd4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "text_piece = \"The food at this place is really good.\"\n",
    "labels = [\"Food\", \"Employee\", \"Restaurant\", \"Party\", \"Nature\", \"Car\"]\n",
    "\n",
    "predictions = classifier(text_piece, labels, multi_label=False)\n",
    "pprint.pprint(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5813cf0a-381a-4635-80de-9ad330c8baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': ['Food', 'Restaurant', 'Employee', 'Car', 'Party', 'Nature'],\n",
      " 'scores': [0.6570188999176025,\n",
      "            0.15241296589374542,\n",
      "            0.10275784134864807,\n",
      "            0.043737687170505524,\n",
      "            0.02707245945930481,\n",
      "            0.01700018160045147],\n",
      " 'sequence': 'The food at this place is really good.'}\n",
      "\n",
      "With template:The diners are in the {}\t\n",
      "{'labels': ['Restaurant', 'Food', 'Employee', 'Party', 'Nature', 'Car'],\n",
      " 'scores': [0.42197585105895996,\n",
      "            0.30330562591552734,\n",
      "            0.10521292686462402,\n",
      "            0.0709242895245552,\n",
      "            0.06462253630161285,\n",
      "            0.03395882248878479],\n",
      " 'sequence': 'The food at this place is really good.'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "text_piece = \"The food at this place is really good.\"\n",
    "labels = [\"Food\", \"Employee\", \"Restaurant\", \"Party\", \"Nature\", \"Car\"]\n",
    "\n",
    "predictions = classifier(text_piece,labels)\n",
    "pprint.pprint(predictions)\n",
    "\n",
    "template = \"The diners are in the {}\"\n",
    "predictions = classifier(text_piece,labels,hypothesis_template=template)\n",
    "\n",
    "print(f'\\nWith template:{template}\\t')\n",
    "pprint.pprint(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1893b877-66bb-4d7c-ab0b-61c06fb746c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': ['Positive', 'Neutral', 'Negative'],\n",
      " 'scores': [0.895370364189148, 0.08658882230520248, 0.01804075390100479],\n",
      " 'sequence': 'The food at this place is really good.'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "text_piece = \"The food at this place is really good.\"\n",
    "labels = [\"Positive\", \"Negative\", \"Neutral\"]\n",
    "template = \"The sentiment of this review is {}\"\n",
    "predictions = classifier(text_piece, \n",
    "           labels, \n",
    "           hypothesis_template=template\n",
    "           )\n",
    "pprint.pprint(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cafc954-8944-4a99-af6b-0eef79928402",
   "metadata": {},
   "source": [
    "# PlayGround"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af13af8-f663-4ab2-82e0-19dc4c994a9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Global Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff31afc7-d0c8-4ee2-b0b0-2349ccf3db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "  prdt_list=['Fluke Gold Level Extended Warranty',\n",
    "            'mailing machine rental',\n",
    "            'Punch, 2-Hole, 20 SHT,BKSV',\n",
    "            'HP 5-YR NBD Onsite DMR DT Only SVC',\n",
    "            'V7550 Splicing Device',\n",
    "            'Treehouse Annual Software Maintenance',\n",
    "            'Curve Fitting Toolbox Maintenance (SUBCF)',\n",
    "            'HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND STAND FOR THE HP M750DN CO',\n",
    "            'Maintenance DB/Text',\n",
    "            'bloomberg Terminal',\n",
    "            'TONER DRUM CARTRIDGES',\n",
    "            '9000258Y, MXM453UJ, LASSEN PROG OFFICE',\n",
    "            'Nexpose Shared Perimeter Security Engine Up To 256 IPs',\n",
    "            '2 Year Secure Site SSL Cert #00006856',\n",
    "            'Fluke Standard Maintenance Advanced package',\n",
    "            'REPLACEMENT RIBBON',\n",
    "            'LANDESK SOFTWARE',\n",
    "            'Exec - IT',\n",
    "            'X-Stamper Custom Message Stamp',\n",
    "            'TeamSite Server Dual CPU Annual Std. Maintenance']\n",
    "  prdt_labels=['Communications Devices and Accessories',\n",
    "          'Components for information technology or broadcasting or telecommunications',\n",
    "          'Computer Equipment and Accessories',\n",
    "          'Data Voice or Multimedia Network Equipment or Platforms and Accessories',\n",
    "          'Software',\n",
    "          'Printing and publishing equipment',\n",
    "          'Audio and visual presentation and composing equipment',\n",
    "          'Human resources services',\n",
    "          'Legal services',\n",
    "          'Real estate services',\n",
    "          'Business administration services',\n",
    "          'Professional engineering services',\n",
    "          'Computer services',\n",
    "          'Information Technology Service Delivery',\n",
    "          'Advertising',\n",
    "          'Writing and translations',\n",
    "          'Telecommunications media services',\n",
    "          'Information services',\n",
    "          'Unknown']\n",
    "  return (prdt_list,prdt_labels)\n",
    "\n",
    "def test_classifier(classifier):\n",
    "      print(f'Model Used is :\\t{classifier.model.name_or_path}')\n",
    "      display(classifier(\n",
    "        [\"This is a course about the Transformers library\",\"I expect to be big entrepreneur soon\"],\n",
    "        candidate_labels=[\"education\", \"politics\", \"business\"]))\n",
    "    \n",
    "def run_zero_shot(classifier):\n",
    "  prdt_list=get_data()[0]\n",
    "  prdt_labels=get_data()[1]\n",
    "  results=classifier(sequences=prdt_list,candidate_labels=prdt_labels,)\n",
    "  df=pd.DataFrame([(result['sequence'],result['labels'][0],result['scores'][0]) for result in results])\n",
    "  return df\n",
    "\n",
    "# def get_model(model_name):\n",
    "#   classifier=pipeline('zero-shot-classification',model=model_name)\n",
    "#   # classifier = pipeline(\"zero-shot-classification\",model=model_name,torch_dtype=torch.float16,device_map=\"auto\",trust_remote_code=True)\n",
    "#   print(f'Model Used is :\\t{classifier.model.name_or_path}')\n",
    "#   print(classifier(\n",
    "#     \"This is a course about the Transformers library\",\n",
    "#     candidate_labels=[\"education\", \"politics\", \"business\"]))\n",
    "#   return classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4adc9e-477c-4813-aa18-643252c204c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Try various Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f6558-fcf7-4fbe-9331-5835d667cb60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Zeroshot models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3813e24-357b-4b8e-a578-c34ebf7f56bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Used is :\tfacebook/bart-large-mnli\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'This is a course about the Transformers library',\n",
       "  'labels': ['education', 'business', 'politics'],\n",
       "  'scores': [0.8445963859558105, 0.11197620630264282, 0.043427351862192154]},\n",
       " {'sequence': 'I expect to be big entrepreneur soon',\n",
       "  'labels': ['business', 'education', 'politics'],\n",
       "  'scores': [0.9925172328948975, 0.0038913714233785868, 0.003591410582885146]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier=pipeline(\"zero-shot-classification\")\n",
    "test_classifier(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1e74c95-8fba-404c-b2ae-be9a5b8cdc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Used is :\tfacebook/bart-large-mnli\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'This is a course about the Transformers library',\n",
       "  'labels': ['education', 'business', 'politics'],\n",
       "  'scores': [0.8445963859558105, 0.11197620630264282, 0.043427351862192154]},\n",
       " {'sequence': 'I expect to be big entrepreneur soon',\n",
       "  'labels': ['business', 'education', 'politics'],\n",
       "  'scores': [0.9925172328948975, 0.0038913714233785868, 0.003591410582885146]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fluke Gold Level Extended Warranty</td>\n",
       "      <td>Data Voice or Multimedia Network Equipment or ...</td>\n",
       "      <td>0.097975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mailing machine rental</td>\n",
       "      <td>Printing and publishing equipment</td>\n",
       "      <td>0.371612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Punch, 2-Hole, 20 SHT,BKSV</td>\n",
       "      <td>Telecommunications media services</td>\n",
       "      <td>0.149075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 5-YR NBD Onsite DMR DT Only SVC</td>\n",
       "      <td>Human resources services</td>\n",
       "      <td>0.127308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V7550 Splicing Device</td>\n",
       "      <td>Audio and visual presentation and composing eq...</td>\n",
       "      <td>0.258200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Treehouse Annual Software Maintenance</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.566898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Curve Fitting Toolbox Maintenance (SUBCF)</td>\n",
       "      <td>Professional engineering services</td>\n",
       "      <td>0.231327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND...</td>\n",
       "      <td>Printing and publishing equipment</td>\n",
       "      <td>0.306218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Maintenance DB/Text</td>\n",
       "      <td>Business administration services</td>\n",
       "      <td>0.202107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bloomberg Terminal</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.389366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TONER DRUM CARTRIDGES</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.144548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9000258Y, MXM453UJ, LASSEN PROG OFFICE</td>\n",
       "      <td>Writing and translations</td>\n",
       "      <td>0.132621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nexpose Shared Perimeter Security Engine Up To...</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.168641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2 Year Secure Site SSL Cert #00006856</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.111072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fluke Standard Maintenance Advanced package</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.112488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>REPLACEMENT RIBBON</td>\n",
       "      <td>Professional engineering services</td>\n",
       "      <td>0.180710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LANDESK SOFTWARE</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.528015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Exec - IT</td>\n",
       "      <td>Information services</td>\n",
       "      <td>0.356144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X-Stamper Custom Message Stamp</td>\n",
       "      <td>Telecommunications media services</td>\n",
       "      <td>0.189393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TeamSite Server Dual CPU Annual Std. Maintenance</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.269446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0  \\\n",
       "0                  Fluke Gold Level Extended Warranty   \n",
       "1                              mailing machine rental   \n",
       "2                          Punch, 2-Hole, 20 SHT,BKSV   \n",
       "3                  HP 5-YR NBD Onsite DMR DT Only SVC   \n",
       "4                               V7550 Splicing Device   \n",
       "5               Treehouse Annual Software Maintenance   \n",
       "6           Curve Fitting Toolbox Maintenance (SUBCF)   \n",
       "7   HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND...   \n",
       "8                                 Maintenance DB/Text   \n",
       "9                                  bloomberg Terminal   \n",
       "10                              TONER DRUM CARTRIDGES   \n",
       "11             9000258Y, MXM453UJ, LASSEN PROG OFFICE   \n",
       "12  Nexpose Shared Perimeter Security Engine Up To...   \n",
       "13              2 Year Secure Site SSL Cert #00006856   \n",
       "14        Fluke Standard Maintenance Advanced package   \n",
       "15                                 REPLACEMENT RIBBON   \n",
       "16                                   LANDESK SOFTWARE   \n",
       "17                                          Exec - IT   \n",
       "18                     X-Stamper Custom Message Stamp   \n",
       "19   TeamSite Server Dual CPU Annual Std. Maintenance   \n",
       "\n",
       "                                                    1         2  \n",
       "0   Data Voice or Multimedia Network Equipment or ...  0.097975  \n",
       "1                   Printing and publishing equipment  0.371612  \n",
       "2                   Telecommunications media services  0.149075  \n",
       "3                            Human resources services  0.127308  \n",
       "4   Audio and visual presentation and composing eq...  0.258200  \n",
       "5                                            Software  0.566898  \n",
       "6                   Professional engineering services  0.231327  \n",
       "7                   Printing and publishing equipment  0.306218  \n",
       "8                    Business administration services  0.202107  \n",
       "9   Components for information technology or broad...  0.389366  \n",
       "10  Components for information technology or broad...  0.144548  \n",
       "11                           Writing and translations  0.132621  \n",
       "12  Components for information technology or broad...  0.168641  \n",
       "13  Components for information technology or broad...  0.111072  \n",
       "14                                           Software  0.112488  \n",
       "15                  Professional engineering services  0.180710  \n",
       "16                                           Software  0.528015  \n",
       "17                               Information services  0.356144  \n",
       "18                  Telecommunications media services  0.189393  \n",
       "19                                           Software  0.269446  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=pipeline(\"zero-shot-classification\",model='facebook/bart-large-mnli')\n",
    "test_classifier(classifier)\n",
    "df_bart=run_zero_shot(classifier)\n",
    "df_bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dd0322b-fdd6-4e23-aea4-5bee8028ebcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa541718ae3149b8bbf1c4e31f121508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0596d78b7d9749709897628187bc7dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/modeling_t5seq.py:   0%|          | 0.00/7.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/sjrhuschlee/flan-t5-base-mnli:\n",
      "- modeling_t5seq.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa2ff1a91e840bdb8536e68119b0052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/894M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f8ff12f9aa4a7c874ab2bc40a7d161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ee0a0ca6a94a0e8c91bdba82ffc642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8510bc895a4253808bbb1a2a318a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed7c55e40b34581aab151003f4f44f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Used is :\tsjrhuschlee/flan-t5-base-mnli\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'This is a course about the Transformers library',\n",
       "  'labels': ['education', 'business', 'politics'],\n",
       "  'scores': [0.9867612719535828, 0.008408918045461178, 0.004829790908843279]},\n",
       " {'sequence': 'I expect to be big entrepreneur soon',\n",
       "  'labels': ['business', 'education', 'politics'],\n",
       "  'scores': [0.9811003804206848, 0.0146280936896801, 0.004271486308425665]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fluke Gold Level Extended Warranty</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.587094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mailing machine rental</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.358135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Punch, 2-Hole, 20 SHT,BKSV</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.328012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 5-YR NBD Onsite DMR DT Only SVC</td>\n",
       "      <td>Computer services</td>\n",
       "      <td>0.203150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V7550 Splicing Device</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.477804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Treehouse Annual Software Maintenance</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.400808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Curve Fitting Toolbox Maintenance (SUBCF)</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.608822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND...</td>\n",
       "      <td>Printing and publishing equipment</td>\n",
       "      <td>0.296451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Maintenance DB/Text</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.606560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bloomberg Terminal</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.602281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TONER DRUM CARTRIDGES</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.532663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9000258Y, MXM453UJ, LASSEN PROG OFFICE</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.363908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nexpose Shared Perimeter Security Engine Up To...</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.522853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2 Year Secure Site SSL Cert #00006856</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.573223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fluke Standard Maintenance Advanced package</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.685639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>REPLACEMENT RIBBON</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.524603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LANDESK SOFTWARE</td>\n",
       "      <td>Real estate services</td>\n",
       "      <td>0.559717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Exec - IT</td>\n",
       "      <td>Information services</td>\n",
       "      <td>0.471302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X-Stamper Custom Message Stamp</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.508799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TeamSite Server Dual CPU Annual Std. Maintenance</td>\n",
       "      <td>Components for information technology or broad...</td>\n",
       "      <td>0.408486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0  \\\n",
       "0                  Fluke Gold Level Extended Warranty   \n",
       "1                              mailing machine rental   \n",
       "2                          Punch, 2-Hole, 20 SHT,BKSV   \n",
       "3                  HP 5-YR NBD Onsite DMR DT Only SVC   \n",
       "4                               V7550 Splicing Device   \n",
       "5               Treehouse Annual Software Maintenance   \n",
       "6           Curve Fitting Toolbox Maintenance (SUBCF)   \n",
       "7   HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND...   \n",
       "8                                 Maintenance DB/Text   \n",
       "9                                  bloomberg Terminal   \n",
       "10                              TONER DRUM CARTRIDGES   \n",
       "11             9000258Y, MXM453UJ, LASSEN PROG OFFICE   \n",
       "12  Nexpose Shared Perimeter Security Engine Up To...   \n",
       "13              2 Year Secure Site SSL Cert #00006856   \n",
       "14        Fluke Standard Maintenance Advanced package   \n",
       "15                                 REPLACEMENT RIBBON   \n",
       "16                                   LANDESK SOFTWARE   \n",
       "17                                          Exec - IT   \n",
       "18                     X-Stamper Custom Message Stamp   \n",
       "19   TeamSite Server Dual CPU Annual Std. Maintenance   \n",
       "\n",
       "                                                    1         2  \n",
       "0   Components for information technology or broad...  0.587094  \n",
       "1   Components for information technology or broad...  0.358135  \n",
       "2   Components for information technology or broad...  0.328012  \n",
       "3                                   Computer services  0.203150  \n",
       "4   Components for information technology or broad...  0.477804  \n",
       "5                                            Software  0.400808  \n",
       "6   Components for information technology or broad...  0.608822  \n",
       "7                   Printing and publishing equipment  0.296451  \n",
       "8   Components for information technology or broad...  0.606560  \n",
       "9   Components for information technology or broad...  0.602281  \n",
       "10  Components for information technology or broad...  0.532663  \n",
       "11  Components for information technology or broad...  0.363908  \n",
       "12                                           Software  0.522853  \n",
       "13  Components for information technology or broad...  0.573223  \n",
       "14  Components for information technology or broad...  0.685639  \n",
       "15  Components for information technology or broad...  0.524603  \n",
       "16                               Real estate services  0.559717  \n",
       "17                               Information services  0.471302  \n",
       "18  Components for information technology or broad...  0.508799  \n",
       "19  Components for information technology or broad...  0.408486  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=pipeline(\"zero-shot-classification\",model='sjrhuschlee/flan-t5-base-mnli',trust_remote_code=True,)\n",
    "test_classifier(classifier)\n",
    "df_flan=run_zero_shot(classifier)\n",
    "df_flan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7010e72-56ac-40c0-9e65-b50343fdfd0c",
   "metadata": {},
   "source": [
    "- **Kills the kernel, try with bigger GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50212f91-ffb1-4272-a26c-4084bdb81a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e048dd483b455682978ed7a199c9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier=pipeline(\"zero-shot-classification\",model='Bschleter/llama-2-7b-hermes-financecompliance',torch_dtype=torch.float16,device_map=\"auto\")\n",
    "test_classifier(classifier)\n",
    "df_llama_hermes=run_zero_shot(classifier)\n",
    "df_llama_hermes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab14829-6a22-471b-8f0d-40cb0d8c3abc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Non-zero shot models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877aabdf-0195-41cf-acaf-28a2b713fc90",
   "metadata": {},
   "source": [
    "- llama-2 not possible to use for zero-shot classification\n",
    "- Need to fine tune on mnli dataset (probably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cf9c74a-d124-468b-aed2-04e9e80d5457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a763e20778b4586ad9cf0ba7f26ecbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5eec5e62a445649b38f26ecdfaf323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759e947e32f245dd9c814cbe0b7b9815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10bb929191f477aafa7f419a87659c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864ac89c11a340d180761c1e5f235fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e2dd7f0f064a03b77f586240a10879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c129119d5124b6584feb161e63e4b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Used is :\tgoogle/flan-t5-base\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You have to specify either decoder_input_ids or decoder_inputs_embeds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m classifier\u001b[38;5;241m=\u001b[39mpipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m,model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoogle/flan-t5-base\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtest_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_flan_chat\u001b[38;5;241m=\u001b[39mrun_zero_shot(classifier)\n\u001b[1;32m      4\u001b[0m df_flan_chat\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mtest_classifier\u001b[0;34m(classifier)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_classifier\u001b[39m(classifier):\n\u001b[1;32m      2\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Used is :\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mclassifier\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mname_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m       display(\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThis is a course about the Transformers library\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI expect to be big entrepreneur soon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meducation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpolitics\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbusiness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/pipelines/zero_shot_classification.py:205\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/pipelines/base.py:1103\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1100\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1101\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1102\u001b[0m     )\n\u001b[0;32m-> 1103\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 266\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/pipelines/base.py:1028\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1027\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1028\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/pipelines/zero_shot_classification.py:224\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline._forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    222\u001b[0m sequence \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    223\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m {k: inputs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mmodel_input_names}\n\u001b[0;32m--> 224\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_label\u001b[39m\u001b[38;5;124m\"\u001b[39m: candidate_label,\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m: sequence,\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutputs,\n\u001b[1;32m    231\u001b[0m }\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1717\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1714\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1717\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1732\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/myGPT/.llmenv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:987\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m     err_msg_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 987\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124minput_ids or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: You have to specify either decoder_input_ids or decoder_inputs_embeds"
     ]
    }
   ],
   "source": [
    "classifier=pipeline(\"zero-shot-classification\",model='google/flan-t5-base')\n",
    "test_classifier(classifier)\n",
    "df_flan_chat=run_zero_shot(classifier)\n",
    "df_flan_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1bc7775-af8f-49b8-acd1-340954050ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48155b6dcac4c009ebdc88e6242ccd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d0c6abd8e34a8c929eafa738afa736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc20f824359469ca42234ed67d04eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ba224e64614f3cbcd0dcf9fc4ae92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d00217142574667a6a1f203cc67c8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1588b27d937440109416b602d760226f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-chat-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b24df06bd042a7b59ce2409c4c57b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d794bd92f23d45f3b8afb9b7272b9006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001771f42b8c4cfaac3ead0ea9519121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90532448f9d24b4b820552899212b6cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Using pad_token, but it is not set yet.\n",
      "Tokenizer was not supporting padding necessary for zero-shot, attempting to use  `pad_token=eos_token`\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Used is :\tmeta-llama/Llama-2-7b-chat-hf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'This is a course about the Transformers library',\n",
       "  'labels': ['politics', 'education', 'business'],\n",
       "  'scores': [0.38658690452575684, 0.36387479305267334, 0.2495383322238922]},\n",
       " {'sequence': 'I expect to be big entrepreneur soon',\n",
       "  'labels': ['education', 'politics', 'business'],\n",
       "  'scores': [0.5809245109558105, 0.25718650221824646, 0.161888986825943]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fluke Gold Level Extended Warranty</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.170759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mailing machine rental</td>\n",
       "      <td>Computer Equipment and Accessories</td>\n",
       "      <td>0.095694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Punch, 2-Hole, 20 SHT,BKSV</td>\n",
       "      <td>Data Voice or Multimedia Network Equipment or ...</td>\n",
       "      <td>0.062951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 5-YR NBD Onsite DMR DT Only SVC</td>\n",
       "      <td>Data Voice or Multimedia Network Equipment or ...</td>\n",
       "      <td>0.072345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V7550 Splicing Device</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.190659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Treehouse Annual Software Maintenance</td>\n",
       "      <td>Computer Equipment and Accessories</td>\n",
       "      <td>0.108944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Curve Fitting Toolbox Maintenance (SUBCF)</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.203226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.061821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Maintenance DB/Text</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.102357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bloomberg Terminal</td>\n",
       "      <td>Computer Equipment and Accessories</td>\n",
       "      <td>0.110765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TONER DRUM CARTRIDGES</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.142057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9000258Y, MXM453UJ, LASSEN PROG OFFICE</td>\n",
       "      <td>Data Voice or Multimedia Network Equipment or ...</td>\n",
       "      <td>0.070999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nexpose Shared Perimeter Security Engine Up To...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.211027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2 Year Secure Site SSL Cert #00006856</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.157274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fluke Standard Maintenance Advanced package</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.122522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>REPLACEMENT RIBBON</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.162733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LANDESK SOFTWARE</td>\n",
       "      <td>Software</td>\n",
       "      <td>0.100687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Exec - IT</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.084534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X-Stamper Custom Message Stamp</td>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.146738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TeamSite Server Dual CPU Annual Std. Maintenance</td>\n",
       "      <td>Computer Equipment and Accessories</td>\n",
       "      <td>0.167001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0  \\\n",
       "0                  Fluke Gold Level Extended Warranty   \n",
       "1                              mailing machine rental   \n",
       "2                          Punch, 2-Hole, 20 SHT,BKSV   \n",
       "3                  HP 5-YR NBD Onsite DMR DT Only SVC   \n",
       "4                               V7550 Splicing Device   \n",
       "5               Treehouse Annual Software Maintenance   \n",
       "6           Curve Fitting Toolbox Maintenance (SUBCF)   \n",
       "7   HP COLOR LASERJET 3X500-SHEET PAPER FEEDER AND...   \n",
       "8                                 Maintenance DB/Text   \n",
       "9                                  bloomberg Terminal   \n",
       "10                              TONER DRUM CARTRIDGES   \n",
       "11             9000258Y, MXM453UJ, LASSEN PROG OFFICE   \n",
       "12  Nexpose Shared Perimeter Security Engine Up To...   \n",
       "13              2 Year Secure Site SSL Cert #00006856   \n",
       "14        Fluke Standard Maintenance Advanced package   \n",
       "15                                 REPLACEMENT RIBBON   \n",
       "16                                   LANDESK SOFTWARE   \n",
       "17                                          Exec - IT   \n",
       "18                     X-Stamper Custom Message Stamp   \n",
       "19   TeamSite Server Dual CPU Annual Std. Maintenance   \n",
       "\n",
       "                                                    1         2  \n",
       "0                                         Advertising  0.170759  \n",
       "1                  Computer Equipment and Accessories  0.095694  \n",
       "2   Data Voice or Multimedia Network Equipment or ...  0.062951  \n",
       "3   Data Voice or Multimedia Network Equipment or ...  0.072345  \n",
       "4                                         Advertising  0.190659  \n",
       "5                  Computer Equipment and Accessories  0.108944  \n",
       "6                                            Software  0.203226  \n",
       "7                                             Unknown  0.061821  \n",
       "8                                            Software  0.102357  \n",
       "9                  Computer Equipment and Accessories  0.110765  \n",
       "10                                            Unknown  0.142057  \n",
       "11  Data Voice or Multimedia Network Equipment or ...  0.070999  \n",
       "12                                            Unknown  0.211027  \n",
       "13                                        Advertising  0.157274  \n",
       "14                                        Advertising  0.122522  \n",
       "15                                        Advertising  0.162733  \n",
       "16                                           Software  0.100687  \n",
       "17                                        Advertising  0.084534  \n",
       "18                                        Advertising  0.146738  \n",
       "19                 Computer Equipment and Accessories  0.167001  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=pipeline(\"zero-shot-classification\",model='meta-llama/Llama-2-7b-chat-hf',torch_dtype=torch.float16,device_map=\"auto\",)\n",
    "test_classifier(classifier)\n",
    "df_llama_chat=run_zero_shot(classifier)\n",
    "df_llama_chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf46ef7f-d40a-4831-b70b-1e7c061a3384",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c25389c-f4d1-4a78-9e9f-db9b3389fc08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_llama_chat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_llama_chat\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_llama_chat' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9324529b-c706-482b-8846-e928be946db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier=pipeline(\"zero-shot-classification\",model='meta-llama/Llama-2-7b-hf',torch_dtype=torch.float16,device_map=\"auto\",trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "326b0a97-629f-403e-9020-5f4ab66186a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bart.columns=['item','label_bart','Prob_bart']\n",
    "# df_llama.columns=['item','label_llama','Prob_llama']\n",
    "# df_flan.columns=['item','label_flan','Prob_flan']\n",
    "# tt=pd.merge(df_bart,df_llama,on='item')\n",
    "# df=pd.merge(tt,df_flan,on='item')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90861da-a7d7-403e-b0ea-ff18ae376370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
